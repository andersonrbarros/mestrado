{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa694969-40c4-4874-8c27-61032e0dca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71929d37-e8ec-40a6-b96e-0ddb7d7d01a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>adicao_ratio</th>\n",
       "      <th>conclusao_ratio</th>\n",
       "      <th>correcao_ratio</th>\n",
       "      <th>restricao_ratio</th>\n",
       "      <th>inclusao_ratio</th>\n",
       "      <th>condicao_ratio</th>\n",
       "      <th>resumo_ratio</th>\n",
       "      <th>certeza_ratio</th>\n",
       "      <th>justificativa_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>simp.similarity_cosine_cbow</th>\n",
       "      <th>simp.similarity_dice</th>\n",
       "      <th>simp.similarity_jaccard</th>\n",
       "      <th>simp.similarity_word_movers_cbow</th>\n",
       "      <th>simp.tf_idf_ngram1</th>\n",
       "      <th>simp.tf_idf_ngram2</th>\n",
       "      <th>simp.tf_idf_ngram3</th>\n",
       "      <th>simp.tf_idf_ngram4</th>\n",
       "      <th>simp.tf_idf_ngram_all</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.047393</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.852286</td>\n",
       "      <td>0.266958</td>\n",
       "      <td>0.154040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.067568</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700030</td>\n",
       "      <td>0.195349</td>\n",
       "      <td>0.108247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661778</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.042146</td>\n",
       "      <td>0.007663</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007663</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.821088</td>\n",
       "      <td>0.268657</td>\n",
       "      <td>0.155172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.048309</td>\n",
       "      <td>0.009662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.829396</td>\n",
       "      <td>0.267303</td>\n",
       "      <td>0.154270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6558</th>\n",
       "      <td>6573</td>\n",
       "      <td>0.052326</td>\n",
       "      <td>0.005814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.669729</td>\n",
       "      <td>0.257778</td>\n",
       "      <td>0.147959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.921</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6559</th>\n",
       "      <td>6574</td>\n",
       "      <td>0.048193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571261</td>\n",
       "      <td>0.236641</td>\n",
       "      <td>0.134199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.916</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6560</th>\n",
       "      <td>6575</td>\n",
       "      <td>0.043165</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>0.010791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.789959</td>\n",
       "      <td>0.270073</td>\n",
       "      <td>0.156118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.953</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6561</th>\n",
       "      <td>6576</td>\n",
       "      <td>0.039711</td>\n",
       "      <td>0.003610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010830</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.610612</td>\n",
       "      <td>0.213523</td>\n",
       "      <td>0.119522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.829</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.923</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6562</th>\n",
       "      <td>6577</td>\n",
       "      <td>0.071186</td>\n",
       "      <td>0.003390</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006780</td>\n",
       "      <td>0.010169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.715797</td>\n",
       "      <td>0.232394</td>\n",
       "      <td>0.131474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.931</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6563 rows × 358 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  adicao_ratio  conclusao_ratio  correcao_ratio  restricao_ratio  \\\n",
       "0        1      0.047393         0.009479        0.000000         0.000000   \n",
       "1        2      0.067568         0.006757        0.006757         0.000000   \n",
       "2        3      0.074074         0.007407        0.000000         0.000000   \n",
       "3        4      0.042146         0.007663        0.000000         0.000000   \n",
       "4        5      0.048309         0.009662        0.000000         0.000000   \n",
       "...    ...           ...              ...             ...              ...   \n",
       "6558  6573      0.052326         0.005814        0.000000         0.000000   \n",
       "6559  6574      0.048193         0.000000        0.000000         0.004016   \n",
       "6560  6575      0.043165         0.003597        0.000000         0.003597   \n",
       "6561  6576      0.039711         0.003610        0.000000         0.003610   \n",
       "6562  6577      0.071186         0.003390        0.000000         0.000000   \n",
       "\n",
       "      inclusao_ratio  condicao_ratio  resumo_ratio  certeza_ratio  \\\n",
       "0           0.000000        0.009479           0.0       0.000000   \n",
       "1           0.000000        0.006757           0.0       0.013514   \n",
       "2           0.007407        0.007407           0.0       0.000000   \n",
       "3           0.007663        0.011494           0.0       0.000000   \n",
       "4           0.000000        0.000000           0.0       0.000000   \n",
       "...              ...             ...           ...            ...   \n",
       "6558        0.000000        0.017442           0.0       0.000000   \n",
       "6559        0.000000        0.016064           0.0       0.000000   \n",
       "6560        0.003597        0.010791           0.0       0.000000   \n",
       "6561        0.000000        0.010830           0.0       0.000000   \n",
       "6562        0.006780        0.010169           0.0       0.000000   \n",
       "\n",
       "      justificativa_ratio  ...  simp.similarity_cosine_cbow  \\\n",
       "0                0.000000  ...                     0.852286   \n",
       "1                0.000000  ...                     0.700030   \n",
       "2                0.007407  ...                     0.661778   \n",
       "3                0.003831  ...                     0.821088   \n",
       "4                0.024155  ...                     0.829396   \n",
       "...                   ...  ...                          ...   \n",
       "6558             0.017442  ...                     0.669729   \n",
       "6559             0.016064  ...                     0.571261   \n",
       "6560             0.010791  ...                     0.789959   \n",
       "6561             0.007220  ...                     0.610612   \n",
       "6562             0.016949  ...                     0.715797   \n",
       "\n",
       "      simp.similarity_dice  simp.similarity_jaccard  \\\n",
       "0                 0.266958                 0.154040   \n",
       "1                 0.195349                 0.108247   \n",
       "2                 0.129032                 0.068966   \n",
       "3                 0.268657                 0.155172   \n",
       "4                 0.267303                 0.154270   \n",
       "...                    ...                      ...   \n",
       "6558              0.257778                 0.147959   \n",
       "6559              0.236641                 0.134199   \n",
       "6560              0.270073                 0.156118   \n",
       "6561              0.213523                 0.119522   \n",
       "6562              0.232394                 0.131474   \n",
       "\n",
       "      simp.similarity_word_movers_cbow  simp.tf_idf_ngram1  \\\n",
       "0                                  0.0               0.990   \n",
       "1                                  0.0               0.985   \n",
       "2                                  0.0               0.955   \n",
       "3                                  0.0               0.990   \n",
       "4                                  0.0               0.993   \n",
       "...                                ...                 ...   \n",
       "6558                               0.0               0.977   \n",
       "6559                               0.0               0.963   \n",
       "6560                               0.0               0.989   \n",
       "6561                               0.0               0.969   \n",
       "6562                               0.0               0.975   \n",
       "\n",
       "      simp.tf_idf_ngram2  simp.tf_idf_ngram3  simp.tf_idf_ngram4  \\\n",
       "0                  0.936               0.588               0.378   \n",
       "1                  0.822               0.447               0.291   \n",
       "2                  0.789               0.375               0.160   \n",
       "3                  0.901               0.513               0.292   \n",
       "4                  0.897               0.569               0.442   \n",
       "...                  ...                 ...                 ...   \n",
       "6558               0.812               0.393               0.145   \n",
       "6559               0.817               0.430               0.195   \n",
       "6560               0.873               0.544               0.361   \n",
       "6561               0.829               0.462               0.252   \n",
       "6562               0.843               0.433               0.201   \n",
       "\n",
       "      simp.tf_idf_ngram_all  score  \n",
       "0                     0.965      0  \n",
       "1                     0.939      0  \n",
       "2                     0.903      0  \n",
       "3                     0.959      0  \n",
       "4                     0.960      0  \n",
       "...                     ...    ...  \n",
       "6558                  0.921    520  \n",
       "6559                  0.916    480  \n",
       "6560                  0.953    600  \n",
       "6561                  0.923    360  \n",
       "6562                  0.931    480  \n",
       "\n",
       "[6563 rows x 358 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataset 1 - Extended-Essay-BR-with-features \n",
    "dataset1 = '/home/arbarros/Mestrado/datasets/essay_br_with_features.csv'\n",
    "extended = pd.read_csv(dataset1)\n",
    "df = pd.DataFrame(extended)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13b0e5be-2de0-49c4-ac61-42bb14ae58f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset balanceado salvo como 'balanced_dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "# Required Libraries\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load Dataset\n",
    "def load_dataset(file_path):\n",
    "    dataset = pd.read_csv(file_path)\n",
    "    return dataset\n",
    "\n",
    "# Distribution Analysis\n",
    "def analyze_score_distribution(dataset):\n",
    "    score_distribution = dataset['score']\n",
    "    bins = [0, 200, 400, 600, 800, 1000]\n",
    "    score_distribution_bins = pd.cut(score_distribution, bins=bins, right=False)\n",
    "    bin_counts = score_distribution_bins.value_counts().sort_index()\n",
    "    return bin_counts\n",
    "\n",
    "# PCA and Clustering\n",
    "def perform_pca_and_clustering(dataset):\n",
    "    features = dataset.drop(columns=[\"id\", \"score\"])\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    features_pca = pca.fit_transform(features_scaled)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "    clusters = kmeans.fit_predict(features_pca)\n",
    "    dataset['cluster'] = clusters\n",
    "    return dataset, features_pca, clusters\n",
    "\n",
    "# Plot Clusters\n",
    "def plot_clusters(features_pca, clusters):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(\n",
    "        x=features_pca[:, 0],\n",
    "        y=features_pca[:, 1],\n",
    "        hue=clusters,\n",
    "        palette=\"Set2\",\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    plt.title(\"Clusters Baseados em Features (Redução PCA)\", fontsize=16)\n",
    "    plt.xlabel(\"Componente Principal 1\", fontsize=12)\n",
    "    plt.ylabel(\"Componente Principal 2\", fontsize=12)\n",
    "    plt.legend(title=\"Cluster\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# Correlation Analysis\n",
    "def analyze_feature_correlations(dataset):\n",
    "    correlations = dataset.corr()[\"score\"].sort_values(ascending=False)\n",
    "    top_positive = correlations.head(11)\n",
    "    top_negative = correlations.tail(10)\n",
    "    return pd.concat([top_positive, top_negative])\n",
    "\n",
    "# Heatmap for Top Correlations\n",
    "def plot_correlation_heatmap(dataset, top_correlations):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(\n",
    "        dataset[top_correlations.index].corr(),\n",
    "        annot=True,\n",
    "        cmap=\"coolwarm\",\n",
    "        fmt=\".2f\",\n",
    "        linewidths=0.5,\n",
    "    )\n",
    "    plt.title(\"Heatmap de Correlações (Principais Features e Score)\", fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "# Generate Synthetic Essay\n",
    "def generate_synthetic_essay(score_target):\n",
    "    introduction = (\n",
    "        \"A educação é um pilar essencial para o desenvolvimento de uma sociedade justa e igualitária. \"\n",
    "        \"No entanto, no Brasil, o acesso à educação de qualidade enfrenta desafios significativos, como \"\n",
    "        \"a desigualdade social e a falta de investimentos.\"\n",
    "    )\n",
    "    \n",
    "    development_1 = (\n",
    "        \"Por um lado, as desigualdades regionais dificultam a universalização do ensino, especialmente \"\n",
    "        \"em áreas rurais e comunidades vulneráveis. A ausência de infraestrutura e professores qualificados \"\n",
    "        \"perpetua o ciclo de exclusão social.\"\n",
    "    )\n",
    "    \n",
    "    development_2 = (\n",
    "        \"Além disso, o investimento público em educação é insuficiente para atender às demandas de um sistema \"\n",
    "        \"cada vez mais sobrecarregado. A valorização dos professores e a ampliação de políticas inclusivas são \"\n",
    "        \"estratégias fundamentais para enfrentar esses desafios.\"\n",
    "    )\n",
    "    \n",
    "    conclusion = (\n",
    "        \"Portanto, é indispensável que o governo priorize investimentos em educação e que a sociedade civil participe \"\n",
    "        \"ativamente desse processo. Só assim será possível construir uma nação onde o acesso ao conhecimento seja um direito \"\n",
    "        \"efetivamente garantido para todos.\"\n",
    "    )\n",
    "    \n",
    "    if score_target < 500:\n",
    "        introduction = introduction.replace(\"desafios significativos\", \"problemas grandes\")\n",
    "        development_1 = development_1.replace(\"universalização do ensino\", \"melhora na educação\")\n",
    "        conclusion = conclusion.replace(\"indispensável\", \"muito importante\")\n",
    "    \n",
    "    elif score_target > 800:\n",
    "        development_2 += (\n",
    "            \" Além disso, é essencial que as escolas contemplem a diversidade cultural do país, promovendo o respeito \"\n",
    "            \"aos direitos humanos e à pluralidade.\"\n",
    "        )\n",
    "        conclusion += \" Essa abordagem fortalece os pilares de uma sociedade justa e inclusiva.\"\n",
    "    \n",
    "    essay = \"\\n\\n\".join([introduction, development_1, development_2, conclusion])\n",
    "    return essay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea3d219-259a-431d-a99a-c63cc26de30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este dataset possui 6563 linhas x 358 colunas . Cada coluna representa uma features extraída por técncias de extração de features PLN.\n",
    "# Coluna score representa o target \n",
    "# Considerando que removi algumas redações por inconsistências, meu dataset limpo ficou com 6536 redações, porém não tem como excluir essas redações apenas pelo id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c96ca24e-42d3-4f40-9bb4-78cdc9000c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1IAAAI2CAYAAABaNLn/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABRB0lEQVR4nO3de1xU1f7/8fdwGy4CCiojimiGmeIt7Ziaede8Hy0vWXnvVJpFSnb82gXLoKzQ0jIrQ8u7HenYsUxNs0w9KWWKllqaiEKUIiAiIOzfHz6Y3xkBdSM5iK/n47Efj2btNXt/trMk3q6911gMwzAEAAAAALhiLs4uAAAAAACuNwQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQCVzsKFC2WxWOybp6enbDabOnfurJiYGKWlpRV7T1RUlCwWi6nznD17VlFRUfrqq69Mva+kc9WrV099+/Y1dZzLWbp0qWbPnl3iPovFoqioqHI9X3n78ssv1bp1a/n4+MhiseiTTz4pte+xY8c0fvx4NWzYUF5eXgoICFDTpk310EMP6dixY9euaCeYNGmSLBZLqeMnLy9PjzzyiGrVqiVXV1e1aNFCJ06cUFRUlHbv3n1Na73Sz6no74iLi4sOHz5c7DjZ2dny8/OTxWLRqFGjSjzPY489pgYNGsjT01PVqlVTp06dtGTJEhmGYe/XqVMnh58VpW1Ff1fq1atXap9OnTqV9x8XgArOzdkFAMBfJS4uTo0aNVJ+fr7S0tK0detWvfLKK3rttde0YsUKdevWzd533Lhxuvvuu00d/+zZs5o+fbokmfolqiznKoulS5cqMTFRERERxfZt375dderU+ctrKCvDMDRkyBA1bNhQa9askY+Pj2655ZYS+yYnJ+u2225T1apVNXnyZN1yyy3KyMjQ/v37tXLlSh0+fFghISHX+Aqujfz8fC1evFiStG7dOh0/fly1a9d26DNv3jzNnz9fc+bMUatWrVSlShWdOHFC06dPV7169dSiRYtrUmtZPqcqVaooLi5OL774okP7qlWrlJ+fL3d392Ln+fbbb9W3b19VqVJFTz31lJo1a6aMjAytXLlSDzzwgD799FMtXbpULi4uevvtt5WZmWl/79q1azVjxgz7z44i//t3pX379nrttdeKndfPz6/MfzYArlMGAFQycXFxhiRj586dxfYdPXrUCAkJMXx9fY3U1NSrOs8ff/xhSDKef/75K+qfnZ1d6r7Q0FCjT58+V1XPxfr06WOEhoaW6zGvleTkZEOS8corr1y273PPPWdIMg4fPlzi/oKCgvIur1Rnz541CgsLr9n5Vq1aZUgy+vTpY0gyXnrppWJ9xo0bZ3h5eTm07dy505BkxMXFlWs9l7p+M5/T888/b0gyxo0bZ4SEhBT7DO+8807jvvvuM3x8fIyRI0fa29PT042aNWsaoaGhJf79fvnllw1JRkxMTIk1XOpnh2H8NX9PAVy/uLUPwA2lbt26ev3115WVlaX58+fb20u63W7Tpk3q1KmTAgMD5eXlpbp16+qee+7R2bNn9dtvv6lGjRqSpOnTp9tv7ym6zajoeN9//73uvfdeVatWTQ0aNCj1XEXi4+PVrFkzeXp66qabbtKbb77psL/otsXffvvNof2rr76SxWKx32bYqVMnrV27VkePHnW4/ahISbf2JSYmasCAAapWrZo8PT3VokULLVq0qMTzLFu2TNOmTVNwcLD8/PzUrVs3HThwoPQ/+P+xdetWde3aVb6+vvL29la7du20du1a+/6oqCj7DMDTTz8ti8WievXqlXq8kydPysXFRTVr1ixxv4uL4//q/vvf/6pfv34KDAyUp6enGjRoUGzW7nI1Sv//s1i/fr3GjBmjGjVqyNvbW7m5uZKkFStWqG3btvLx8VGVKlXUs2dP/fDDDw7HOHz4sIYNG6bg4GBZrVYFBQWpa9euV3zL3YIFC+Th4aG4uDiFhIQoLi7O4dY1i8Wi999/Xzk5OfYxsHDhQt1+++2SpNGjRxe7fU2Sdu3apf79+ysgIECenp5q2bKlVq5caer6L2b2c5KkMWPG6NixY9qwYYO97eDBg9q6davGjBlTrP/777+vtLQ0vfzyywoKCiq2f8qUKWrUqJFeffVV5efnl1gHAFwpghSAG07v3r3l6uqqr7/+utQ+v/32m/r06SMPDw998MEHWrdunV5++WX5+PgoLy9PtWrV0rp16yRJY8eO1fbt27V9+3Y9++yzDscZNGiQbr75Zq1atUrvvPPOJevavXu3IiIi9OSTTyo+Pl7t2rXTE088UeJtRJfz9ttvq3379rLZbPbatm/fXmr/AwcOqF27dtq3b5/efPNNrV69Wo0bN9aoUaM0c+bMYv3/7//+T0ePHtX777+vd999V4cOHVK/fv1UUFBwybq2bNmiLl26KCMjQwsWLNCyZcvk6+urfv36acWKFZIu3Pq4evVqSdLEiRO1fft2xcfHl3rMtm3bqrCwUIMGDdIXX3zhcKvWxb744gt16NBBSUlJio2N1eeff65nnnlGv//+u6ka/9eYMWPk7u6ujz76SB9//LHc3d0VHR2t++67T40bN9bKlSv10UcfKSsrSx06dND+/fvt7+3du7cSEhI0c+ZMbdiwQfPmzVPLli11+vTpS/45ShdulVu/fr0GDBigGjVqaOTIkfrll18cxvX27dvVu3dveXl52cdA586dFRcXJ0l65pln7O3jxo2TJG3evFnt27fX6dOn9c477+jf//63WrRooaFDh2rhwoVXdP0lMfM5FQkLC1OHDh30wQcf2Ns++OAD1atXT127di3Wf8OGDXJ1dVW/fv1KPJ7FYlH//v116tQpJSQkXPb8JTEMQ+fPny+2/W+ABXCDcPKMGACUu8vdnmMYhhEUFGTceuut9tdFtxIV+fjjjw1Jxu7du0s9xqVu7Ss63nPPPVfqvv8VGhpqWCyWYufr3r274efnZ78tsOjajhw54tBv8+bNhiRj8+bN9rZL3dp3cd3Dhg0zrFarkZSU5NCvV69ehre3t3H69GmH8/Tu3duh38qVKw1Jxvbt20s8X5E77rjDqFmzppGVlWVvO3/+vBEeHm7UqVPHflvYkSNHDEnGq6++esnjGYZhFBYWGg8//LDh4uJiSDIsFotx6623Gk8++WSxP6cGDRoYDRo0MHJycq66xqLPYsSIEQ7vT0pKMtzc3IyJEyc6tGdlZRk2m80YMmSIYRiG8eeffxqSjNmzZ1/2GkvywgsvGJKMdevWGYZhGIcPHzYsFovx4IMPOvQbOXKk4ePj49B2qVv7GjVqZLRs2dLIz893aO/bt69Rq1Yt+212pV1/acx8TkV/R/744w8jLi7OsFqtxsmTJ43z588btWrVMqKiogzDMIrd2teoUSPDZrNdso558+YZkowVK1YU23clt/ZJKnF78cUXr+jPAUDlwYwUgBuScZl/PW7RooU8PDz0j3/8Q4sWLSpx5bArcc8991xx3yZNmqh58+YObcOHD1dmZqa+//77Mp3/Sm3atEldu3Yt9rD/qFGjdPbs2WKzWf3793d43axZM0nS0aNHSz1Hdna2/vvf/+ree+9VlSpV7O2urq568MEHlZycfMW3B/4vi8Wid955R4cPH9bbb7+t0aNHKz8/X7NmzVKTJk20ZcsWSRduCfv11181duxYeXp6lluNF3/GX3zxhc6fP68RI0Y4zFh4enqqY8eO9tsvAwIC1KBBA7366quKjY3VDz/8oMLCwiu6ZsMw7Lfzde/eXZJUv359derUSf/617+uaLanJL/88ot+/vln3X///ZLkUH/v3r2VkpJy2esvzZV+ThcbPHiwPDw8tGTJEn322WdKTU0tcaW+K1X0d9/sKp1F7rzzTu3cubPYNnbs2DLXBOD6RJACcMPJzs7WyZMnFRwcXGqfBg0aaOPGjapZs6YmTJigBg0aqEGDBnrjjTdMnatWrVpX3Ndms5XadvLkSVPnNevkyZMl1lr0Z3Tx+QMDAx1eW61WSVJOTk6p50hPT5dhGKbOY0ZoaKgeffRRLViwQIcOHdKKFSt07tw5PfXUU5KkP/74Q5IuuVphWWq8uG/RbYK333673N3dHbYVK1bozz//lHThF/kvv/xSPXv21MyZM3XbbbepRo0aevzxx5WVlXXJa920aZOOHDmiwYMHKzMzU6dPn9bp06c1ZMgQnT17VsuWLbvk+0tTVHtkZGSx2sePHy9J9vpLu/7LudzndDEfHx8NHTpUH3zwgRYsWKBu3bopNDS0xL5169bVH3/8oezs7FLPX/R8YVlXcvT391fr1q2LbWb/HABc/1j+HMANZ+3atSooKLjskuUdOnRQhw4dVFBQoF27dmnOnDmKiIhQUFCQhg0bdkXnMvOv3qmpqaW2FQWXopmUix/ov/iXW7MCAwOVkpJSrP3EiROSpOrVq1/V8SWpWrVqcnFx+cvPU2TIkCGKiYlRYmKiJNkXB0lOTi7XGi/+jIv2f/zxx6X+wl8kNDRUCxYskHRhxmzlypWKiopSXl7eJZ+pK3pPbGysYmNjS9z/8MMPX/LcJSmqferUqRo0aFCJfS5ehr6sMztFLv6cSjJmzBi9//772rNnj5YsWVJqv+7du2v9+vX69NNPS/w7ahiG1qxZo4CAALVq1eqq6gYAZqQA3FCSkpIUGRkpf3//K/5F09XVVW3atNFbb70lSfbb7K5kFsaMffv26ccff3RoW7p0qXx9fXXbbbdJkn31uj179jj0W7NmTbHjWa3WK66ta9eu2rRpkz0sFPnwww/l7e2tO+6440ovo1Q+Pj5q06aNVq9e7VBXYWGhFi9erDp16qhhw4amj1tS6JGkM2fO6NixY/aZpIYNG6pBgwb64IMPSl1Zrjxq7Nmzp9zc3PTrr7+WOHPRunXrEt/XsGFDPfPMM2ratOklb+VMT09XfHy82rdvr82bNxfb7r//fu3cufOSwaS0sXvLLbcoLCxMP/74Y6m1+/r6XvL6S3Oln1NJ2rZtqzFjxmjgwIEaOHBgqf3GjRunmjVraurUqSV+8fbMmTP1888/a8qUKaUuigEAV4oZKQCVVmJiov35jrS0NH3zzTeKi4uTq6ur4uPj7TMUJXnnnXe0adMm9enTR3Xr1tW5c+fsK4cVfZGvr6+vQkND9e9//1tdu3ZVQECAqlevfsmlui8lODhY/fv3V1RUlGrVqqXFixdrw4YNeuWVV+Tt7S3pwu1it9xyiyIjI3X+/HlVq1ZN8fHx2rp1a7HjNW3aVKtXr9a8efPUqlUrubi4lPpL/PPPP6///Oc/6ty5s5577jkFBARoyZIlWrt2rWbOnCl/f/8yXdPFYmJi1L17d3Xu3FmRkZHy8PDQ22+/rcTERC1btqxMsxsvvfSSvv32Ww0dOlQtWrSQl5eXjhw5orlz5+rkyZN69dVX7X3feust9evXT3fccYeefPJJ1a1bV0lJSfriiy/sMx1XW2O9evX0wgsvaNq0aTp8+LDuvvtuVatWTb///ru+++47+fj4aPr06dqzZ48ee+wxDR48WGFhYfLw8NCmTZu0Z88e/fOf/yz1+EuWLNG5c+f0+OOPlzirGhgYqCVLlmjBggWaNWtWicdo0KCBvLy8tGTJEt16662qUqWKgoODFRwcrPnz56tXr17q2bOnRo0apdq1a+vUqVP66aef9P3332vVqlVX8KkUZ+ZzKknRLNylVK1aVatXr1bfvn3VqlUrPfXUU2revLkyMzO1YsUKLVmyREOHDi31NsIrcfr0ae3YsaNYu9VqVcuWLct8XADXIWeudAEAf4WilbeKNg8PD6NmzZpGx44djejoaCMtLa3Yey5eSW/79u3GwIEDjdDQUMNqtRqBgYFGx44djTVr1ji8b+PGjUbLli0Nq9VqSLKvIPa/q45d7lyG8f+/6PPjjz82mjRpYnh4eBj16tUzYmNji73/4MGDRo8ePQw/Pz+jRo0axsSJE421a9cWW7Xv1KlTxr333mtUrVrVsFgsDudUCasN7t271+jXr5/h7+9veHh4GM2bNy+2qlvRqn2rVq1yaC9aZe9KvuD1m2++Mbp06WL4+PgYXl5exh133GF8+umnJR7vSlbt27FjhzFhwgSjefPmRkBAgOHq6mrUqFHDuPvuu43PPvusWP/t27cbvXr1Mvz9/Q2r1Wo0aNDAePLJJ03XeLkV3j755BOjc+fOhp+fn2G1Wo3Q0FDj3nvvNTZu3GgYhmH8/vvvxqhRo4xGjRoZPj4+RpUqVYxmzZoZs2bNMs6fP1/q9bZo0cKoWbOmkZubW2qfO+64w6hevbqRm5tb4qp9hmEYy5YtMxo1amS4u7sXGw8//vijMWTIEKNmzZqGu7u7YbPZjC5duhjvvPPOFV//xcx8Tpf6+/O/Ll61r0hSUpIxYcIE46abbjI8PDwMf39/46677jIWL158yS9MvppV+2rXrn35PwQAlYrFMPjiAwAAAAAwg2ekAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEl8Ia8ufGP9iRMn5OvrW6YvgwQAAABQORiGoaysLAUHB8vFpfR5J4KUpBMnTigkJMTZZQAAAACoII4dO6Y6deqUup8gJcnX11fShT8sPz8/J1cDAAAAwFkyMzMVEhJizwilIUhJ9tv5/Pz8CFIAAAAALvvID4tNAAAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpCqgN9LfcHYJf6nKfn03gmv9GVb286H8VfYxwxi9/lX2MVPZz3cj4DO8PIIUAAAAAJhEkAIAAAAAkwhSAAAAAGCSU4NUvXr1ZLFYim0TJkyQJBmGoaioKAUHB8vLy0udOnXSvn37HI6Rm5uriRMnqnr16vLx8VH//v2VnJzsjMsBAAAAcINwapDauXOnUlJS7NuGDRskSYMHD5YkzZw5U7GxsZo7d6527twpm82m7t27Kysry36MiIgIxcfHa/ny5dq6davOnDmjvn37qqCgwCnXBAAAAKDyc2qQqlGjhmw2m337z3/+owYNGqhjx44yDEOzZ8/WtGnTNGjQIIWHh2vRokU6e/asli5dKknKyMjQggUL9Prrr6tbt25q2bKlFi9erL1792rjxo3OvDQAAAAAlViFeUYqLy9Pixcv1pgxY2SxWHTkyBGlpqaqR48e9j5Wq1UdO3bUtm3bJEkJCQnKz8936BMcHKzw8HB7n5Lk5uYqMzPTYQMAAACAK1VhgtQnn3yi06dPa9SoUZKk1NRUSVJQUJBDv6CgIPu+1NRUeXh4qFq1aqX2KUlMTIz8/f3tW0hISDleCQAAAIDKrsIEqQULFqhXr14KDg52aLdYLA6vDcMo1naxy/WZOnWqMjIy7NuxY8fKXjgAAACAG06FCFJHjx7Vxo0bNW7cOHubzWaTpGIzS2lpafZZKpvNpry8PKWnp5fapyRWq1V+fn4OGwAAAABcqQoRpOLi4lSzZk316dPH3la/fn3ZbDb7Sn7SheeotmzZonbt2kmSWrVqJXd3d4c+KSkpSkxMtPcBAAAAgPLm5uwCCgsLFRcXp5EjR8rN7f+XY7FYFBERoejoaIWFhSksLEzR0dHy9vbW8OHDJUn+/v4aO3asJk+erMDAQAUEBCgyMlJNmzZVt27dnHVJAAAAACo5pwepjRs3KikpSWPGjCm2b8qUKcrJydH48eOVnp6uNm3aaP369fL19bX3mTVrltzc3DRkyBDl5OSoa9euWrhwoVxdXa/lZQAAAAC4gTg9SPXo0UOGYZS4z2KxKCoqSlFRUaW+39PTU3PmzNGcOXP+ogoBAAAAwFGFeEYKAAAAAK4nBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmOT1IHT9+XA888IACAwPl7e2tFi1aKCEhwb7fMAxFRUUpODhYXl5e6tSpk/bt2+dwjNzcXE2cOFHVq1eXj4+P+vfvr+Tk5Gt9KQAAAABuEE4NUunp6Wrfvr3c3d31+eefa//+/Xr99ddVtWpVe5+ZM2cqNjZWc+fO1c6dO2Wz2dS9e3dlZWXZ+0RERCg+Pl7Lly/X1q1bdebMGfXt21cFBQVOuCoAAAAAlZ2bM0/+yiuvKCQkRHFxcfa2evXq2f/bMAzNnj1b06ZN06BBgyRJixYtUlBQkJYuXaqHH35YGRkZWrBggT766CN169ZNkrR48WKFhIRo48aN6tmzZ7Hz5ubmKjc31/46MzPzL7pCAAAAAJWRU2ek1qxZo9atW2vw4MGqWbOmWrZsqffee8++/8iRI0pNTVWPHj3sbVarVR07dtS2bdskSQkJCcrPz3foExwcrPDwcHufi8XExMjf39++hYSE/EVXCAAAAKAycmqQOnz4sObNm6ewsDB98cUXeuSRR/T444/rww8/lCSlpqZKkoKCghzeFxQUZN+XmpoqDw8PVatWrdQ+F5s6daoyMjLs27Fjx8r70gAAAABUYk69ta+wsFCtW7dWdHS0JKlly5bat2+f5s2bpxEjRtj7WSwWh/cZhlGs7WKX6mO1WmW1Wq+yegAAAAA3KqfOSNWqVUuNGzd2aLv11luVlJQkSbLZbJJUbGYpLS3NPktls9mUl5en9PT0UvsAAAAAQHlyapBq3769Dhw44NB28OBBhYaGSpLq168vm82mDRs22Pfn5eVpy5YtateunSSpVatWcnd3d+iTkpKixMREex8AAAAAKE9OvbXvySefVLt27RQdHa0hQ4bou+++07vvvqt3331X0oVb+iIiIhQdHa2wsDCFhYUpOjpa3t7eGj58uCTJ399fY8eO1eTJkxUYGKiAgABFRkaqadOm9lX8AAAAAKA8OTVI3X777YqPj9fUqVP1wgsvqH79+po9e7buv/9+e58pU6YoJydH48ePV3p6utq0aaP169fL19fX3mfWrFlyc3PTkCFDlJOTo65du2rhwoVydXV1xmUBAAAAqOScGqQkqW/fvurbt2+p+y0Wi6KiohQVFVVqH09PT82ZM0dz5sz5CyoEAAAAAEdOfUYKAAAAAK5HBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJBCkAAAAAMMmpQSoqKkoWi8Vhs9ls9v2GYSgqKkrBwcHy8vJSp06dtG/fPodj5ObmauLEiapevbp8fHzUv39/JScnX+tLAQAAAHADcfqMVJMmTZSSkmLf9u7da983c+ZMxcbGau7cudq5c6dsNpu6d++urKwse5+IiAjFx8dr+fLl2rp1q86cOaO+ffuqoKDAGZcDAAAA4Abg5vQC3NwcZqGKGIah2bNna9q0aRo0aJAkadGiRQoKCtLSpUv18MMPKyMjQwsWLNBHH32kbt26SZIWL16skJAQbdy4UT179rym1wIAAADgxuD0GalDhw4pODhY9evX17Bhw3T48GFJ0pEjR5SamqoePXrY+1qtVnXs2FHbtm2TJCUkJCg/P9+hT3BwsMLDw+19SpKbm6vMzEyHDQAAAACulFODVJs2bfThhx/qiy++0HvvvafU1FS1a9dOJ0+eVGpqqiQpKCjI4T1BQUH2fampqfLw8FC1atVK7VOSmJgY+fv727eQkJByvjIAAAAAlZlTg1SvXr10zz33qGnTpurWrZvWrl0r6cItfEUsFovDewzDKNZ2scv1mTp1qjIyMuzbsWPHruIqAAAAANxonH5r3//y8fFR06ZNdejQIftzUxfPLKWlpdlnqWw2m/Ly8pSenl5qn5JYrVb5+fk5bAAAAABwpSpUkMrNzdVPP/2kWrVqqX79+rLZbNqwYYN9f15enrZs2aJ27dpJklq1aiV3d3eHPikpKUpMTLT3AQAAAIDy5tRV+yIjI9WvXz/VrVtXaWlpmjFjhjIzMzVy5EhZLBZFREQoOjpaYWFhCgsLU3R0tLy9vTV8+HBJkr+/v8aOHavJkycrMDBQAQEBioyMtN8qCAAAAAB/BacGqeTkZN133336888/VaNGDd1xxx3asWOHQkNDJUlTpkxRTk6Oxo8fr/T0dLVp00br16+Xr6+v/RizZs2Sm5ubhgwZopycHHXt2lULFy6Uq6ursy4LAAAAQCXn1CC1fPnyS+63WCyKiopSVFRUqX08PT01Z84czZkzp5yrAwAAAICSVahnpAAAAADgekCQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJBCkAAAAAMKlMQerIkSPlXQcAAAAAXDfKFKRuvvlmde7cWYsXL9a5c+fKuyYAAAAAqNDKFKR+/PFHtWzZUpMnT5bNZtPDDz+s7777rrxrAwAAAIAKqUxBKjw8XLGxsTp+/Lji4uKUmpqqO++8U02aNFFsbKz++OOP8q4TAAAAACqMq1psws3NTQMHDtTKlSv1yiuv6Ndff1VkZKTq1KmjESNGKCUlpbzqBAAAAIAK46qC1K5duzR+/HjVqlVLsbGxioyM1K+//qpNmzbp+PHjGjBgQHnVCQAAAAAVhltZ3hQbG6u4uDgdOHBAvXv31ocffqjevXvLxeVCLqtfv77mz5+vRo0alWuxAAAAAFARlClIzZs3T2PGjNHo0aNls9lK7FO3bl0tWLDgqooDAAAAgIqoTEHq0KFDl+3j4eGhkSNHluXwAAAAAFChlekZqbi4OK1atapY+6pVq7Ro0aKrLgoAAAAAKrIyBamXX35Z1atXL9Zes2ZNRUdHX3VRAAAAAFCRlSlIHT16VPXr1y/WHhoaqqSkpKsuCgAAAAAqsjIFqZo1a2rPnj3F2n/88UcFBgZedVEAAAAAUJGVKUgNGzZMjz/+uDZv3qyCggIVFBRo06ZNeuKJJzRs2LAyFRITEyOLxaKIiAh7m2EYioqKUnBwsLy8vNSpUyft27fP4X25ubmaOHGiqlevLh8fH/Xv31/JycllqgEAAAAArkSZgtSMGTPUpk0bde3aVV5eXvLy8lKPHj3UpUuXMj0jtXPnTr377rtq1qyZQ/vMmTMVGxuruXPnaufOnbLZbOrevbuysrLsfSIiIhQfH6/ly5dr69atOnPmjPr27auCgoKyXBoAAAAAXFaZgpSHh4dWrFihn3/+WUuWLNHq1av166+/6oMPPpCHh4epY505c0b333+/3nvvPVWrVs3ebhiGZs+erWnTpmnQoEEKDw/XokWLdPbsWS1dulSSlJGRoQULFuj1119Xt27d1LJlSy1evFh79+7Vxo0by3JpAAAAAHBZZQpSRRo2bKjBgwerb9++Cg0NLdMxJkyYoD59+qhbt24O7UeOHFFqaqp69Ohhb7NarerYsaO2bdsmSUpISFB+fr5Dn+DgYIWHh9v7lCQ3N1eZmZkOGwAAAABcqTJ9IW9BQYEWLlyoL7/8UmlpaSosLHTYv2nTpis6zvLly/X9999r586dxfalpqZKkoKCghzag4KCdPToUXsfDw8Ph5msoj5F7y9JTEyMpk+ffkU1AgAAAMDFyhSknnjiCS1cuFB9+vRReHi4LBaL6WMcO3ZMTzzxhNavXy9PT89S+118bMMwLnu+y/WZOnWqJk2aZH+dmZmpkJCQK6wcAAAAwI2uTEFq+fLlWrlypXr37l3mEyckJCgtLU2tWrWytxUUFOjrr7/W3LlzdeDAAUkXZp1q1apl75OWlmafpbLZbMrLy1N6errDrFRaWpratWtX6rmtVqusVmuZawcAAABwYyvzYhM333zzVZ24a9eu2rt3r3bv3m3fWrdurfvvv1+7d+/WTTfdJJvNpg0bNtjfk5eXpy1btthDUqtWreTu7u7QJyUlRYmJiZcMUgAAAABwNco0IzV58mS98cYbmjt3bplu65MkX19fhYeHO7T5+PgoMDDQ3h4REaHo6GiFhYUpLCxM0dHR8vb21vDhwyVJ/v7+Gjt2rCZPnqzAwEAFBAQoMjJSTZs2LbZ4BQAAAACUlzIFqa1bt2rz5s36/PPP1aRJE7m7uzvsX716dbkUN2XKFOXk5Gj8+PFKT09XmzZttH79evn6+tr7zJo1S25ubhoyZIhycnLUtWtXLVy4UK6uruVSAwAAAABcrExBqmrVqho4cGB516KvvvrK4bXFYlFUVJSioqJKfY+np6fmzJmjOXPmlHs9AAAAAFCSMgWpuLi48q4DAAAAAK4bZf5C3vPnz2vjxo2aP3++srKyJEknTpzQmTNnyq04AAAAAKiIyjQjdfToUd19991KSkpSbm6uunfvLl9fX82cOVPnzp3TO++8U951AgAAAECFUaYZqSeeeEKtW7dWenq6vLy87O0DBw7Ul19+WW7FAQAAAEBFVOZV+7799lt5eHg4tIeGhur48ePlUhgAAAAAVFRlmpEqLCxUQUFBsfbk5GSHpckBAAAAoDIqU5Dq3r27Zs+ebX9tsVh05swZPf/88+rdu3d51QYAAAAAFVKZbu2bNWuWOnfurMaNG+vcuXMaPny4Dh06pOrVq2vZsmXlXSMAAAAAVChlClLBwcHavXu3li1bpu+//16FhYUaO3as7r//fofFJwAAAACgMipTkJIkLy8vjRkzRmPGjCnPegAAAACgwitTkPrwww8vuX/EiBFlKgYAAAAArgdlClJPPPGEw+v8/HydPXtWHh4e8vb2JkgBAAAAqNTKtGpfenq6w3bmzBkdOHBAd955J4tNAAAAAKj0yhSkShIWFqaXX3652GwVAAAAAFQ25RakJMnV1VUnTpwoz0MCAAAAQIVTpmek1qxZ4/DaMAylpKRo7ty5at++fbkUBgAAAAAVVZmC1N///neH1xaLRTVq1FCXLl30+uuvl0ddAAAAAFBhlSlIFRYWlncdAAAAAHDdKNdnpAAAAADgRlCmGalJkyZdcd/Y2NiynAIAAAAAKqwyBakffvhB33//vc6fP69bbrlFknTw4EG5urrqtttus/ezWCzlUyUAAAAAVCBlClL9+vWTr6+vFi1apGrVqkm68CW9o0ePVocOHTR58uRyLRIAAAAAKpIyPSP1+uuvKyYmxh6iJKlatWqaMWMGq/YBAAAAqPTKFKQyMzP1+++/F2tPS0tTVlbWVRcFAAAAABVZmYLUwIEDNXr0aH388cdKTk5WcnKyPv74Y40dO1aDBg0q7xoBAAAAoEIp0zNS77zzjiIjI/XAAw8oPz//woHc3DR27Fi9+uqr5VogAAAAAFQ0ZQpS3t7eevvtt/Xqq6/q119/lWEYuvnmm+Xj41Pe9QEAAABAhXNVX8ibkpKilJQUNWzYUD4+PjIMo7zqAgAAAIAKq0xB6uTJk+ratasaNmyo3r17KyUlRZI0btw4lj4HAAAAUOmVKUg9+eSTcnd3V1JSkry9ve3tQ4cO1bp168qtOAAAAACoiMr0jNT69ev1xRdfqE6dOg7tYWFhOnr0aLkUBgAAAAAVVZlmpLKzsx1moor8+eefslqtV10UAAAAAFRkZQpSd911lz788EP7a4vFosLCQr366qvq3LlzuRUHAAAAABVRmW7te/XVV9WpUyft2rVLeXl5mjJlivbt26dTp07p22+/Le8aAQAAAKBCKdOMVOPGjbVnzx797W9/U/fu3ZWdna1Bgwbphx9+UIMGDcq7RgAAAACoUEzPSOXn56tHjx6aP3++pk+f/lfUBAAAAAAVmukZKXd3dyUmJspisfwV9QAAAABAhVemW/tGjBihBQsWlHctAAAAAHBdKNNiE3l5eXr//fe1YcMGtW7dWj4+Pg77Y2Njy6U4AAAAAKiITAWpw4cPq169ekpMTNRtt90mSTp48KBDH275AwAAAFDZmQpSYWFhSklJ0ebNmyVJQ4cO1ZtvvqmgoKC/pDgAAAAAqIhMPSNlGIbD688//1zZ2dnlWhAAAAAAVHRlWmyiyMXBCgAAAABuBKaClMViKfYMFM9EAQAAALjRmHpGyjAMjRo1SlarVZJ07tw5PfLII8VW7Vu9enX5VQgAAAAAFYypIDVy5EiH1w888EC5FgMAAAAA1wNTQSouLu6vqgMAAAAArhtXtdgEAAAAANyICFIAAAAAYBJBCgAAAABMIkgBAAAAgElODVLz5s1Ts2bN5OfnJz8/P7Vt21aff/65fb9hGIqKilJwcLC8vLzUqVMn7du3z+EYubm5mjhxoqpXry4fHx/1799fycnJ1/pSAAAAANxAnBqk6tSpo5dfflm7du3Srl271KVLFw0YMMAelmbOnKnY2FjNnTtXO3fulM1mU/fu3ZWVlWU/RkREhOLj47V8+XJt3bpVZ86cUd++fVVQUOCsywIAAABQyTk1SPXr10+9e/dWw4YN1bBhQ7300kuqUqWKduzYIcMwNHv2bE2bNk2DBg1SeHi4Fi1apLNnz2rp0qWSpIyMDC1YsECvv/66unXrppYtW2rx4sXau3evNm7c6MxLAwAAAFCJVZhnpAoKCrR8+XJlZ2erbdu2OnLkiFJTU9WjRw97H6vVqo4dO2rbtm2SpISEBOXn5zv0CQ4OVnh4uL1PSXJzc5WZmemwAQAAAMCVcnqQ2rt3r6pUqSKr1apHHnlE8fHxaty4sVJTUyVJQUFBDv2DgoLs+1JTU+Xh4aFq1aqV2qckMTEx8vf3t28hISHlfFUAAAAAKjOnB6lbbrlFu3fv1o4dO/Too49q5MiR2r9/v32/xWJx6G8YRrG2i12uz9SpU5WRkWHfjh07dnUXAQAAAOCG4vQg5eHhoZtvvlmtW7dWTEyMmjdvrjfeeEM2m02Sis0spaWl2WepbDab8vLylJ6eXmqfklitVvtKgUUbAAAAAFwppwepixmGodzcXNWvX182m00bNmyw78vLy9OWLVvUrl07SVKrVq3k7u7u0CclJUWJiYn2PgAAAABQ3tycefL/+7//U69evRQSEqKsrCwtX75cX331ldatWyeLxaKIiAhFR0crLCxMYWFhio6Olre3t4YPHy5J8vf319ixYzV58mQFBgYqICBAkZGRatq0qbp16+bMSwMAAABQiTk1SP3+++968MEHlZKSIn9/fzVr1kzr1q1T9+7dJUlTpkxRTk6Oxo8fr/T0dLVp00br16+Xr6+v/RizZs2Sm5ubhgwZopycHHXt2lULFy6Uq6ursy4LAAAAQCXn1CC1YMGCS+63WCyKiopSVFRUqX08PT01Z84czZkzp5yrAwAAAICSVbhnpAAAAACgoiNIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJTg1SMTExuv322+Xr66uaNWvq73//uw4cOODQxzAMRUVFKTg4WF5eXurUqZP27dvn0Cc3N1cTJ05U9erV5ePjo/79+ys5OflaXgoAAACAG4hTg9SWLVs0YcIE7dixQxs2bND58+fVo0cPZWdn2/vMnDlTsbGxmjt3rnbu3Cmbzabu3bsrKyvL3iciIkLx8fFavny5tm7dqjNnzqhv374qKChwxmUBAAAAqOTcnHnydevWObyOi4tTzZo1lZCQoLvuukuGYWj27NmaNm2aBg0aJElatGiRgoKCtHTpUj388MPKyMjQggUL9NFHH6lbt26SpMWLFyskJEQbN25Uz549r/l1AQAAAKjcKtQzUhkZGZKkgIAASdKRI0eUmpqqHj162PtYrVZ17NhR27ZtkyQlJCQoPz/foU9wcLDCw8PtfS6Wm5urzMxMhw0AAAAArlSFCVKGYWjSpEm68847FR4eLklKTU2VJAUFBTn0DQoKsu9LTU2Vh4eHqlWrVmqfi8XExMjf39++hYSElPflAAAAAKjEKkyQeuyxx7Rnzx4tW7as2D6LxeLw2jCMYm0Xu1SfqVOnKiMjw74dO3as7IUDAAAAuOFUiCA1ceJErVmzRps3b1adOnXs7TabTZKKzSylpaXZZ6lsNpvy8vKUnp5eap+LWa1W+fn5OWwAAAAAcKWcGqQMw9Bjjz2m1atXa9OmTapfv77D/vr168tms2nDhg32try8PG3ZskXt2rWTJLVq1Uru7u4OfVJSUpSYmGjvAwAAAADlyamr9k2YMEFLly7Vv//9b/n6+tpnnvz9/eXl5SWLxaKIiAhFR0crLCxMYWFhio6Olre3t4YPH27vO3bsWE2ePFmBgYEKCAhQZGSkmjZtal/FDwAAAADKk1OD1Lx58yRJnTp1cmiPi4vTqFGjJElTpkxRTk6Oxo8fr/T0dLVp00br16+Xr6+vvf+sWbPk5uamIUOGKCcnR127dtXChQvl6up6rS4FAAAAwA3EqUHKMIzL9rFYLIqKilJUVFSpfTw9PTVnzhzNmTOnHKsDAAAAgJJViMUmAAAAAOB6QpACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgklOD1Ndff61+/fopODhYFotFn3zyicN+wzAUFRWl4OBgeXl5qVOnTtq3b59Dn9zcXE2cOFHVq1eXj4+P+vfvr+Tk5Gt4FQAAAABuNE4NUtnZ2WrevLnmzp1b4v6ZM2cqNjZWc+fO1c6dO2Wz2dS9e3dlZWXZ+0RERCg+Pl7Lly/X1q1bdebMGfXt21cFBQXX6jIAAAAA3GDcnHnyXr16qVevXiXuMwxDs2fP1rRp0zRo0CBJ0qJFixQUFKSlS5fq4YcfVkZGhhYsWKCPPvpI3bp1kyQtXrxYISEh2rhxo3r27HnNrgUAAADAjaPCPiN15MgRpaamqkePHvY2q9Wqjh07atu2bZKkhIQE5efnO/QJDg5WeHi4vU9JcnNzlZmZ6bABAAAAwJWqsEEqNTVVkhQUFOTQHhQUZN+XmpoqDw8PVatWrdQ+JYmJiZG/v799CwkJKefqAQAAAFRmFTZIFbFYLA6vDcMo1naxy/WZOnWqMjIy7NuxY8fKpVYAAAAAN4YKG6RsNpskFZtZSktLs89S2Ww25eXlKT09vdQ+JbFarfLz83PYAAAAAOBKVdggVb9+fdlsNm3YsMHelpeXpy1btqhdu3aSpFatWsnd3d2hT0pKihITE+19AAAAAKC8OXXVvjNnzuiXX36xvz5y5Ih2796tgIAA1a1bVxEREYqOjlZYWJjCwsIUHR0tb29vDR8+XJLk7++vsWPHavLkyQoMDFRAQIAiIyPVtGlT+yp+AAAAAFDenBqkdu3apc6dO9tfT5o0SZI0cuRILVy4UFOmTFFOTo7Gjx+v9PR0tWnTRuvXr5evr6/9PbNmzZKbm5uGDBminJwcde3aVQsXLpSrq+s1vx4AAAAANwanBqlOnTrJMIxS91ssFkVFRSkqKqrUPp6enpozZ47mzJnzF1QIAAAAAMVV2GekAAAAAKCiIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwqdIEqbffflv169eXp6enWrVqpW+++cbZJQEAAACopCpFkFqxYoUiIiI0bdo0/fDDD+rQoYN69eqlpKQkZ5cGAAAAoBKqFEEqNjZWY8eO1bhx43Trrbdq9uzZCgkJ0bx585xdGgAAAIBKyM3ZBVytvLw8JSQk6J///KdDe48ePbRt27YS35Obm6vc3Fz764yMDElSZmbmX1eoCecyzynTtWLU8leo7Nd3I7jWn2FlPx/KX2UfM4zR619lHzOV/Xw3ghv5MyzKBIZhXLKfxbhcjwruxIkTql27tr799lu1a9fO3h4dHa1FixbpwIEDxd4TFRWl6dOnX8syAQAAAFxHjh07pjp16pS6/7qfkSpisVgcXhuGUaytyNSpUzVp0iT768LCQp06dUqBgYGlvudayczMVEhIiI4dOyY/Pz+n1oLrA2MGZjFmYBZjBmYxZmBGRRsvhmEoKytLwcHBl+x33Qep6tWry9XVVampqQ7taWlpCgoKKvE9VqtVVqvVoa1q1ap/VYll4ufnVyEGEq4fjBmYxZiBWYwZmMWYgRkVabz4+/tfts91v9iEh4eHWrVqpQ0bNji0b9iwweFWPwAAAAAoL9f9jJQkTZo0SQ8++KBat26ttm3b6t1331VSUpIeeeQRZ5cGAAAAoBKqFEFq6NChOnnypF544QWlpKQoPDxcn332mUJDQ51dmmlWq1XPP/98sVsPgdIwZmAWYwZmMWZgFmMGZlyv4+W6X7UPAAAAAK616/4ZKQAAAAC41ghSAAAAAGASQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgVUGcP39e+fn5zi4DAAAAwBUgSFUA+/fv1/33368uXbpo9OjRWrZsmbNLAgAAACqUivatTXyPlJMdPHhQf/vb39SvXz+FhYXpyy+/VFZWlpo3b664uDhnl4frzMGDBzV//nylp6erfv36euCBB1SvXj1ZLBZnl4YKiPECsxgzMIsxg6uRmpqqEydO6MyZM7rzzjvl4lKx5oAIUk5kGIaeffZZHThwQKtWrZIknT17VnFxcZo/f75uvfVWrVixwslV4nqxf/9+tW3bVh06dJCfn582bNigRo0a6cEHH9S4ceMq3A8fOBfjBWYxZmAWYwZXY8+ePRo0aJAkKTMzUzVq1NArr7yiDh06yN/f38nVXUCQcrLRo0frl19+0TfffGNvy8nJ0dKlS/XWW2+pZ8+eiomJcWKFuB7k5eVp5MiR8vHx0fvvvy9J+vPPPzV+/HgdO3ZMw4YN08SJE/mfFiQxXmAeYwZmMWZwNX7//Xe1b99eQ4cO1QMPPCA3Nzc9/fTT+v777zVx4kSNHj1aAQEBzi6TZ6ScpSi/3nbbbSooKNDPP/9s3+fl5aXBgwere/fu2rx5s9LS0pxVJq4THh4eOn36tKxWqySpoKBA1atX1zvvvKOGDRtq5cqV+uyzz5xcJSoKxgvMYszALMYMrsaJEyckSQ888IBuvfVWhYWFafXq1fr73/+u+fPna8WKFcrLy3NylQQppym6N7h37946dOiQZs6cqaysLPt+Pz8/RUREaOfOndq2bZuzysR1oLCwUPn5+fL29tbx48clSa6ursrPz1dAQIBiY2MlSfPmzXNmmaggGC8wizEDsxgzuFoZGRlKT0+Xm5ubpAuPvkjS7Nmz1blzZ82YMUPJycmSnLwAhQGn27Rpk2G1Wo0JEyYYf/zxh739zz//NFq1amVs3rzZecXhurFt2zbDYrEYsbGx9rbc3FzDMAzjhx9+MKxWq5GQkOCs8lDBMF5gFmMGZjFmUFYFBQVG48aNjQEDBtjbzp07Z//vli1bGmPGjHFCZY7cnBfhUKRz585atWqVBg8erBMnTmjw4MFq1qyZPvroIyUnJ6tBgwbOLhEVTFJSkvbu3auUlBT17t1bvr6+atu2rWbMmKEpU6bIw8NDEyZMkIeHh6QL/zpYr169CvNwJq4txgvMYszALMYMrkZ2drY8PDx0/vx5eXl5ycXFRTNnztSjjz6qxx9/XG+++aasVqvy8vLk4eGh1q1bKyMjw9lliyBVQfTr10/btm3TpEmT9M9//lNubm5yd3fX559/rpCQEGeXhwpkz5496tGjh4KDg3XkyBG98MILGjp0qJ544gn985//1NmzZ/XEE0/o+PHjGjNmjPz8/LR69WoVFBTI19fX2eXjGmO8wCzGDMxizOBqJCYmasKECcrJydGff/6pyZMnq2/fvurVq5ciIiI0b948/eMf/9C7775rD+Jnz56Vl5eXCgoK5OLi4rzl9J09JQZHGRkZxpEjR4y9e/c63OYHGIZhpKenG61atTKeeuop49SpU4ZhGMb06dONO++80xgwYIBx9OhRwzAMIy4uzvD39zfq1KljNGzY0Khduza3T9yAGC8wizEDsxgzuBqHDx82qlWrZjz22GPGwoULjalTpxq1a9c2hg0bZiQkJBj5+fnGvHnzjFq1ahktWrQwHnroIWP48OGGj4+PkZiY6OzyDZY/B64jSUlJuuuuu/Tuu++qR48e9vYPP/xQ77//vkJCQhQbG6ugoCAdP35ce/fulYuLixo3bqw6deo4sXI4A+MFZjFmYBZjBldj1qxZio+P19dff21vi4+P12uvvaaaNWvqxRdfVHh4uA4fPqwXX3xRZ86cUZUqVRQZGakmTZo4sfILuLUPuI64urrKy8vLvizo+fPn5ebmphEjRujcuXOaO3euvvjiC40YMUK1a9dW7dq1nVwxnMlisTBeYIqLiwtjBqYwZnA1CgsLdfr0aWVlZcnHx0cuLi4aOHCgPDw89Pzzz2v+/Pl65ZVXdNNNNykuLk7ShaX0XV1dnVz5BcxIAdeZ/v3769ixY9q8ebOqVq1q/5+WJA0ePFjHjx9nyfwbWEpKitLT09W4cWNJF56/TE5OZrygVGfPnpW7u7vc3d0lSQMGDFBSUhJjBleMnzMoqxUrVmjUqFHaunWrWrVqZV9MQrowqzlu3Dht375drVq1sr/HMAznPRN1Eb5HCqjAsrOzlZWVpczMTHvbBx98oIyMDA0ZMkR5eXn2/1lJUs+ePWUYRoX4kjpce8ePH1fTpk31zDPPaMeOHZKkuLg4nT59mvGCEiUmJuq+++7Tjh07lJ2dLUlasGABP2NQquTkZK1YsUL/+te/9MMPP0i68HOGMYOyGDp0qHr06KGBAwcqLS1NHh4eys3NlSSNGDFCYWFh+vLLLx3eU1FClESQAiqs/fv3a9CgQerYsaNuvfVWLVmyRIWFhapevbqWLl2qn3/+WT169NCBAwd07tw5SdJ3330nX19f5345HZzm4MGDysjIUEZGhubNm6edO3eqevXqWrZsmRITE9WlSxfGC+z27dunu+66S3Xq1NFNN90kHx8fSbL/jNm3bx8/Y+Bg7969uvPOO/Xaa69pwoQJioqK0qFDh+xj5qeffmLMoFQHDhzQpEmTNGzYML388svatWuXpAvPSQUHB+uOO+7QsWPHZLVaJUnnzp2Tj4+Pqlev7syyL4lb+4AKaP/+/brrrrs0YsQI3X777dq1a5fmzJmj//73v2rZsqWkC/+SPHz4cJ09e1bVqlVTrVq19NVXX+mbb75R8+bNnXwFcIZTp05p9OjR6tOnj+bPn69GjRrpmWee0a233qo9e/ZowoQJOnHihAICAhgvN7js7GwNGjRIDRo00Ntvvy1J+vnnn3Xu3DnVqFFDtWvX1r59+zRkyBDl5ubyMwY6evSo2rdvrwcffFDPPPOMvv76a40ZM0Zr1qzR7bffLkmMGZRq//79ateunTp06KCqVatq48aNuvnmm3XvvffqiSee0L59+/Too49qz549iomJkZ+fn/bu3av33ntP3333XYX9TlWCFFDBnDp1Svfdd58aNWqkN954w97epUsXNW3aVG+88YbD/cFvvfWWkpOT5eXlpaFDh+qWW25xVulwooKCAp06dUp33nmnNm3apO+++04xMTFq3ry59u/fr5tvvlmLFi3SnDlzdOLECcbLDS43N1fdunXTm2++qWbNmqlPnz46deqUfv75ZzVu3FgPPfSQxo4dK0maO3eujh8/zpi5wc2fP1/Lly/Xpk2b7P//6dOnjwYMGCCr1arQ0FB16tRJkvg5Awf5+fkaN26c3N3d9f7770u6sNpjTEyMduzYoWHDhunpp5/W2bNnNW3aNK1bt06GYSggIEBvvfWW/R+QKyJW7QMqmPz8fJ0+fVr33nuvpAsr2ri4uOimm27SyZMnJV24P7ho1ZoJEyY4s1xUEC4uLqpRo4Zuv/12JSYmauDAgbJarRo5cqTOnTun0aNHS5ImTpzo5EpREZw+fVoHDhzQn3/+qaeeekqS9N577yklJUWbNm3SM888I29vb91333167LHHnFwtKgLDMJSUlKTdu3erZcuWeumll/T5558rLy9Pp0+fVlJSkmbMmKGHHnqInzNw4O7urpSUFIWEhEi6MJbq1q2r5557TjNnztTq1asVEhKi4cOHa9asWXrqqafk7e0ti8Uif39/J1d/aTwjBVQwQUFBWrx4sTp06CDpwkyDJNWuXVsuLv//r6yrq6uysrLsr5lcvrEV/Quxq6urvvrqK0nS6tWrVVBQoLp162r79u32BSgkxsuNrmbNmuratavWrFmjQ4cO6cknn1Tz5s1199136/HHH1e3bt309ddf6/z58yosLJTEmLnR9ezZUzabTUOGDNG9996rZ599VvHx8Vq/fr3Wrl2rYcOGaenSpfrzzz8ZM7ArKChQfn6+6tSpo/T0dPuzc4WFhapVq5aefPJJBQYGasWKFfb31KpVS1WrVq3wIUoiSAEVUlhYmKQLP2iKliQuKCjQ77//bu8TExOj9957T+fPn5dUsVaxwbVX9AtLly5d5OHhofHjx+uzzz5TQkKCZsyYoS1btmjRokX21ZAYLzc2i8WiyZMnKy4uTmvXrnVYUa1OnToKCgrS/v375erqav8HHMbMja1+/fpasmSJYmJi1LRpU91zzz0aMGCALBaLatasqeDgYKWnp6tKlSqMGdj/EdjV1VXu7u4aOXKk1qxZo3fffVcWi0UuLi4qLCxU3bp1NX36dH366afavXu3pOtr3HBrH1CBubi42J+Hslgs9i+ge+655zRjxgz98MMPDsvM4sZV9D+e+vXra/To0QoKCtJ//vMf1a9fX/Xr15fFYlHz5s3tqyEBrVu31ueff66OHTvq3Xff1U033aQmTZpIunCLccOGDXX+/Hn7P+YA9erVU7169XT69Gnt3LnT4Tt/fv/9d9WrV8/+CzRuXAcPHtSnn36q4cOHq1atWpKkjh076pVXXtGTTz4pb29vjRs3zh64q1SposaNG8vb29uZZZcJv4EBFVxRkHJ1dVVISIhee+01zZw5U7t27WIVJBTTtm1bvf/++2rdurWaNWtmHz9///vfnV0aKqAOHTroq6++0n333acxY8aoadOmysvL05o1a7R161ZCFErUrl07RUZG6o033pDNZlNiYqLi4uL09ddf25fRx43pl19+Udu2bZWenq6TJ09q0qRJ9uXLH330UWVnZ+sf//iHfvvtNw0cOFChoaH68MMPlZOTc13cyncxVu0DrhMvvfSSnn32Wfn5+Wnjxo1q3bq1s0tCBVW0QAlwpQ4cOKDFixdrx44dCgsL0/jx4xUeHu7sslCBbd68WQ899JBcXFxUu3ZtvfHGG2rWrJmzy4ITZWdn6/HHH1dhYaFat26tiRMnKjIyUk899ZRq1Kgh6cL/n5YsWaIpU6bIxcVFfn5+ysrK0qefflqhV+crDUEKuE7s2rVLf/vb35SYmKjGjRs7uxwAlVDRIgEEcVyJU6dOKT8/X1arVVWrVnV2OXCynJwcxcXFKTAwUEOHDtXKlSs1bNiwYmFKkn777TclJSUpJydH4eHhql27thMrLzuCFHAdyc7O5rYJAABQIV38e8qKFSt03333afLkyXr66adVvXp1nT9/XidOnFDdunWdWGn54Bkp4DpCiAIAABVV0e8pBQUFcnFx0dChQ2UYhoYPHy6LxaKIiAi99tprOnr0qD788EP790Vdr5iRAgAAAFCuDMOQYRhycXHRihUr9OCDD+qmm27Sr7/+qp07d6pFixbOLvGqEaQAAAAAlLuimGGxWNS1a1ft3r1bX331lZo2berkysoHt/YBAAAAKHcWi0UFBQV66qmntHnzZu3evbvShChJYlkeAAAAAH+ZJk2a6Pvvv690S+Rzax8AAACAv0zRl8NXNsxIAQAAAPjLVMYQJRGkAAAAAMA0ghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAKgU0tLS9PDDD6tu3bqyWq2y2Wzq2bOntm/f7uzSAACVkJuzCwAAoDzcc889ys/P16JFi3TTTTfp999/15dffqlTp079JefLy8uTh4fHX3JsAEDFx4wUAOC6d/r0aW3dulWvvPKKOnfurNDQUP3tb3/T1KlT1adPH3uff/zjHwoKCpKnp6fCw8P1n//8x36Mf/3rX2rSpImsVqvq1aun119/3eEc9erV04wZMzRq1Cj5+/vroYcekiRt27ZNd911l7y8vBQSEqLHH39c2dnZ1+7iAQBOQZACAFz3qlSpoipVquiTTz5Rbm5usf2FhYXq1auXtm3bpsWLF2v//v16+eWX5erqKklKSEjQkCFDNGzYMO3du1dRUVF69tlntXDhQofjvPrqqwoPD1dCQoKeffZZ7d27Vz179tSgQYO0Z88erVixQlu3btVjjz12LS4bAOBEFsMwDGcXAQDA1frXv/6lhx56SDk5ObrtttvUsWNHDRs2TM2aNdP69evVq1cv/fTTT2rYsGGx995///36448/tH79envblClTtHbtWu3bt0/ShRmpli1bKj4+3t5nxIgR8vLy0vz58+1tW7duVceOHZWdnS1PT8+/8IoBAM7EjBQAoFK45557dOLECa1Zs0Y9e/bUV199pdtuu00LFy7U7t27VadOnRJDlCT99NNPat++vUNb+/btdejQIRUUFNjbWrdu7dAnISFBCxcutM+IValSRT179lRhYaGOHDlS/hcJAKgwWGwCAFBpeHp6qnv37urevbuee+45jRs3Ts8//7wiIyMv+T7DMGSxWIq1XczHx8fhdWFhoR5++GE9/vjjxfrWrVu3DFcAALheEKQAAJVW48aN9cknn6hZs2ZKTk7WwYMHS5yVaty4sbZu3erQtm3bNjVs2ND+HFVJbrvtNu3bt08333xzudcOAKjYuLUPAHDdO3nypLp06aLFixdrz549OnLkiFatWqWZM2dqwIAB6tixo+666y7dc8892rBhg44cOaLPP/9c69atkyRNnjxZX375pV588UUdPHhQixYt0ty5cy87k/X0009r+/btmjBhgnbv3q1Dhw5pzZo1mjhx4rW4bACAEzEjBQC47lWpUkVt2rTRrFmz9Ouvvyo/P18hISF66KGH9H//93+SLixGERkZqfvuu0/Z2dm6+eab9fLLL0u6MLO0cuVKPffcc3rxxRdVq1YtvfDCCxo1atQlz9usWTNt2bJF06ZNU4cOHWQYhho0aKChQ4f+1ZcMAHAyVu0DAAAAAJO4tQ8AAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADDp/wHZRdvf0ChmzwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df.drop(columns=['id', 'score'])  # Remove 'id' and 'score' for feature set\n",
    "y = df['score']\n",
    "\n",
    "# Apply SMOTE to balance the dataset\n",
    "smote = SMOTE(random_state=42, k_neighbors = 3)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Convert back to DataFrame for analysis\n",
    "balanced_data = pd.concat([pd.DataFrame(X_resampled, columns=X.columns), pd.DataFrame(y_resampled, columns=['score'])], axis=1)\n",
    "\n",
    "# Analyze the distribution of 'score' after SMOTE\n",
    "balanced_score_distribution = balanced_data['score'].value_counts().sort_index()\n",
    "\n",
    "# Plot the distribution after SMOTE\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(balanced_score_distribution.index, balanced_score_distribution.values, color='lightgreen')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Scores After SMOTE')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43a4b66a-0c5f-48c4-916f-e5dad188e81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>adicao_ratio</th>\n",
       "      <th>conclusao_ratio</th>\n",
       "      <th>correcao_ratio</th>\n",
       "      <th>restricao_ratio</th>\n",
       "      <th>inclusao_ratio</th>\n",
       "      <th>condicao_ratio</th>\n",
       "      <th>resumo_ratio</th>\n",
       "      <th>certeza_ratio</th>\n",
       "      <th>justificativa_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>simp.similarity_cosine_cbow</th>\n",
       "      <th>simp.similarity_dice</th>\n",
       "      <th>simp.similarity_jaccard</th>\n",
       "      <th>simp.similarity_word_movers_cbow</th>\n",
       "      <th>simp.tf_idf_ngram1</th>\n",
       "      <th>simp.tf_idf_ngram2</th>\n",
       "      <th>simp.tf_idf_ngram3</th>\n",
       "      <th>simp.tf_idf_ngram4</th>\n",
       "      <th>simp.tf_idf_ngram_all</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.047393</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.852286</td>\n",
       "      <td>0.266958</td>\n",
       "      <td>0.154040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>0.588000</td>\n",
       "      <td>0.378000</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.067568</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700030</td>\n",
       "      <td>0.195349</td>\n",
       "      <td>0.108247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.822000</td>\n",
       "      <td>0.447000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.939000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661778</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.955000</td>\n",
       "      <td>0.789000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.903000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.042146</td>\n",
       "      <td>0.007663</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007663</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.821088</td>\n",
       "      <td>0.268657</td>\n",
       "      <td>0.155172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.901000</td>\n",
       "      <td>0.513000</td>\n",
       "      <td>0.292000</td>\n",
       "      <td>0.959000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.048309</td>\n",
       "      <td>0.009662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.829396</td>\n",
       "      <td>0.267303</td>\n",
       "      <td>0.154270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.993000</td>\n",
       "      <td>0.897000</td>\n",
       "      <td>0.569000</td>\n",
       "      <td>0.442000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17820</th>\n",
       "      <td>5987</td>\n",
       "      <td>0.051284</td>\n",
       "      <td>0.002944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006210</td>\n",
       "      <td>0.001794</td>\n",
       "      <td>0.003266</td>\n",
       "      <td>0.005381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.793656</td>\n",
       "      <td>0.259652</td>\n",
       "      <td>0.149306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.991000</td>\n",
       "      <td>0.892724</td>\n",
       "      <td>0.535851</td>\n",
       "      <td>0.332526</td>\n",
       "      <td>0.956161</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17821</th>\n",
       "      <td>4560</td>\n",
       "      <td>0.067533</td>\n",
       "      <td>0.004108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>0.006152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>0.014328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.842779</td>\n",
       "      <td>0.284191</td>\n",
       "      <td>0.165676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.992648</td>\n",
       "      <td>0.919295</td>\n",
       "      <td>0.615490</td>\n",
       "      <td>0.416453</td>\n",
       "      <td>0.968648</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17822</th>\n",
       "      <td>4552</td>\n",
       "      <td>0.062957</td>\n",
       "      <td>0.003061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003061</td>\n",
       "      <td>0.006122</td>\n",
       "      <td>0.005376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.913011</td>\n",
       "      <td>0.239928</td>\n",
       "      <td>0.136407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994874</td>\n",
       "      <td>0.927390</td>\n",
       "      <td>0.638042</td>\n",
       "      <td>0.371695</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17823</th>\n",
       "      <td>4550</td>\n",
       "      <td>0.044349</td>\n",
       "      <td>0.010952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.007236</td>\n",
       "      <td>0.011345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003618</td>\n",
       "      <td>0.011050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.794593</td>\n",
       "      <td>0.296390</td>\n",
       "      <td>0.174036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.987095</td>\n",
       "      <td>0.908446</td>\n",
       "      <td>0.618493</td>\n",
       "      <td>0.395695</td>\n",
       "      <td>0.963159</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17824</th>\n",
       "      <td>6387</td>\n",
       "      <td>0.037021</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>0.002965</td>\n",
       "      <td>0.009078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004670</td>\n",
       "      <td>0.019049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.802115</td>\n",
       "      <td>0.196392</td>\n",
       "      <td>0.109115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.994073</td>\n",
       "      <td>0.887207</td>\n",
       "      <td>0.535574</td>\n",
       "      <td>0.302537</td>\n",
       "      <td>0.958841</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17825 rows × 358 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  adicao_ratio  conclusao_ratio  correcao_ratio  restricao_ratio  \\\n",
       "0         1      0.047393         0.009479        0.000000         0.000000   \n",
       "1         2      0.067568         0.006757        0.006757         0.000000   \n",
       "2         3      0.074074         0.007407        0.000000         0.000000   \n",
       "3         4      0.042146         0.007663        0.000000         0.000000   \n",
       "4         5      0.048309         0.009662        0.000000         0.000000   \n",
       "...     ...           ...              ...             ...              ...   \n",
       "17820  5987      0.051284         0.002944        0.000000         0.001472   \n",
       "17821  4560      0.067533         0.004108        0.000000         0.000000   \n",
       "17822  4552      0.062957         0.003061        0.000000         0.003061   \n",
       "17823  4550      0.044349         0.010952        0.000000         0.000049   \n",
       "17824  6387      0.037021         0.005300        0.000000         0.000630   \n",
       "\n",
       "       inclusao_ratio  condicao_ratio  resumo_ratio  certeza_ratio  \\\n",
       "0            0.000000        0.009479      0.000000       0.000000   \n",
       "1            0.000000        0.006757      0.000000       0.013514   \n",
       "2            0.007407        0.007407      0.000000       0.000000   \n",
       "3            0.007663        0.011494      0.000000       0.000000   \n",
       "4            0.000000        0.000000      0.000000       0.000000   \n",
       "...               ...             ...           ...            ...   \n",
       "17820        0.000000        0.006210      0.001794       0.003266   \n",
       "17821        0.004783        0.006152      0.000000       0.001369   \n",
       "17822        0.006122        0.005376      0.000000       0.000000   \n",
       "17823        0.007236        0.011345      0.000000       0.003618   \n",
       "17824        0.002965        0.009078      0.000000       0.004670   \n",
       "\n",
       "       justificativa_ratio  ...  simp.similarity_cosine_cbow  \\\n",
       "0                 0.000000  ...                     0.852286   \n",
       "1                 0.000000  ...                     0.700030   \n",
       "2                 0.007407  ...                     0.661778   \n",
       "3                 0.003831  ...                     0.821088   \n",
       "4                 0.024155  ...                     0.829396   \n",
       "...                    ...  ...                          ...   \n",
       "17820             0.005381  ...                     0.793656   \n",
       "17821             0.014328  ...                     0.842779   \n",
       "17822             0.012905  ...                     0.913011   \n",
       "17823             0.011050  ...                     0.794593   \n",
       "17824             0.019049  ...                     0.802115   \n",
       "\n",
       "       simp.similarity_dice  simp.similarity_jaccard  \\\n",
       "0                  0.266958                 0.154040   \n",
       "1                  0.195349                 0.108247   \n",
       "2                  0.129032                 0.068966   \n",
       "3                  0.268657                 0.155172   \n",
       "4                  0.267303                 0.154270   \n",
       "...                     ...                      ...   \n",
       "17820              0.259652                 0.149306   \n",
       "17821              0.284191                 0.165676   \n",
       "17822              0.239928                 0.136407   \n",
       "17823              0.296390                 0.174036   \n",
       "17824              0.196392                 0.109115   \n",
       "\n",
       "       simp.similarity_word_movers_cbow  simp.tf_idf_ngram1  \\\n",
       "0                                   0.0            0.990000   \n",
       "1                                   0.0            0.985000   \n",
       "2                                   0.0            0.955000   \n",
       "3                                   0.0            0.990000   \n",
       "4                                   0.0            0.993000   \n",
       "...                                 ...                 ...   \n",
       "17820                               0.0            0.991000   \n",
       "17821                               0.0            0.992648   \n",
       "17822                               0.0            0.994874   \n",
       "17823                               0.0            0.987095   \n",
       "17824                               0.0            0.994073   \n",
       "\n",
       "       simp.tf_idf_ngram2  simp.tf_idf_ngram3  simp.tf_idf_ngram4  \\\n",
       "0                0.936000            0.588000            0.378000   \n",
       "1                0.822000            0.447000            0.291000   \n",
       "2                0.789000            0.375000            0.160000   \n",
       "3                0.901000            0.513000            0.292000   \n",
       "4                0.897000            0.569000            0.442000   \n",
       "...                   ...                 ...                 ...   \n",
       "17820            0.892724            0.535851            0.332526   \n",
       "17821            0.919295            0.615490            0.416453   \n",
       "17822            0.927390            0.638042            0.371695   \n",
       "17823            0.908446            0.618493            0.395695   \n",
       "17824            0.887207            0.535574            0.302537   \n",
       "\n",
       "       simp.tf_idf_ngram_all  score  \n",
       "0                   0.965000      0  \n",
       "1                   0.939000      0  \n",
       "2                   0.903000      0  \n",
       "3                   0.959000      0  \n",
       "4                   0.960000      0  \n",
       "...                      ...    ...  \n",
       "17820               0.956161   1000  \n",
       "17821               0.968648   1000  \n",
       "17822               0.975000   1000  \n",
       "17823               0.963159   1000  \n",
       "17824               0.958841   1000  \n",
       "\n",
       "[17825 rows x 358 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataset 2 - Extended-Essay-BR-with-features balanceado \n",
    "dataset2 = '/home/arbarros/Mestrado/datasets/dataset_balanceado.csv'\n",
    "balanceado = pd.read_csv(dataset2)\n",
    "df_balanceado = pd.DataFrame(balanceado)\n",
    "\n",
    "df_balanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd23b887-0e0e-418c-baf2-2ad90e5bcd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redações sintéticas salvas como 'redacoes_sinteticas.csv'.\n"
     ]
    }
   ],
   "source": [
    "def gerar_redacao(features):\n",
    "    texto = []\n",
    "\n",
    "    # Criar regras para mapear as features\n",
    "    complexidade = features.get('complexidade_lexical', 0.5)\n",
    "    conectores = features.get('uso_conectores', 0.5)\n",
    "    coerencia = features.get('coerencia_textual', 0.5)\n",
    "\n",
    "    if complexidade > 0.7:\n",
    "        texto.append(\"O texto apresenta vocabulário rico e variado.\")\n",
    "    else:\n",
    "        texto.append(\"O texto utiliza linguagem mais simples e direta.\")\n",
    "\n",
    "    if conectores > 0.7:\n",
    "        texto.append(\"Além disso, conectores são usados de forma consistente para ligar as ideias.\")\n",
    "    else:\n",
    "        texto.append(\"A transição entre ideias poderia ser mais fluida.\")\n",
    "\n",
    "    if coerencia > 0.7:\n",
    "        texto.append(\"A argumentação é clara e bem estruturada.\")\n",
    "    else:\n",
    "        texto.append(\"Há alguns pontos que dificultam a clareza da argumentação.\")\n",
    "\n",
    "    return \" \".join(texto)\n",
    "\n",
    "# Aplicar a geração para cada linha no dataset balanceado\n",
    "redacoes_sinteticas = []\n",
    "for _, row in df_resampled.iterrows():\n",
    "    features = row.to_dict()\n",
    "    redacao = gerar_redacao(features)\n",
    "    redacoes_sinteticas.append({'texto': redacao, 'score': row['score']})\n",
    "\n",
    "# Criar um DataFrame com os textos gerados\n",
    "df_redacoes = pd.DataFrame(redacoes_sinteticas)\n",
    "df_redacoes.to_csv('redacoes_sinteticas.csv', index=False)\n",
    "print(\"Redações sintéticas salvas como 'redacoes_sinteticas.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f3a3b40-bca8-4bf7-89d8-931a757fbad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O texto utiliza linguagem mais simples e diret...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O texto utiliza linguagem mais simples e diret...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O texto utiliza linguagem mais simples e diret...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O texto utiliza linguagem mais simples e diret...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O texto utiliza linguagem mais simples e diret...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17820</th>\n",
       "      <td>O texto utiliza linguagem mais simples e diret...</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17821</th>\n",
       "      <td>O texto utiliza linguagem mais simples e diret...</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17822</th>\n",
       "      <td>O texto utiliza linguagem mais simples e diret...</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17823</th>\n",
       "      <td>O texto utiliza linguagem mais simples e diret...</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17824</th>\n",
       "      <td>O texto utiliza linguagem mais simples e diret...</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17825 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   texto   score\n",
       "0      O texto utiliza linguagem mais simples e diret...     0.0\n",
       "1      O texto utiliza linguagem mais simples e diret...     0.0\n",
       "2      O texto utiliza linguagem mais simples e diret...     0.0\n",
       "3      O texto utiliza linguagem mais simples e diret...     0.0\n",
       "4      O texto utiliza linguagem mais simples e diret...     0.0\n",
       "...                                                  ...     ...\n",
       "17820  O texto utiliza linguagem mais simples e diret...  1000.0\n",
       "17821  O texto utiliza linguagem mais simples e diret...  1000.0\n",
       "17822  O texto utiliza linguagem mais simples e diret...  1000.0\n",
       "17823  O texto utiliza linguagem mais simples e diret...  1000.0\n",
       "17824  O texto utiliza linguagem mais simples e diret...  1000.0\n",
       "\n",
       "[17825 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataset 3 - Extended-Essay-BR-with-features balanceado \n",
    "dataset3 = '/home/arbarros/Mestrado/datasets/redacoes_sinteticas.csv'\n",
    "sinteticas = pd.read_csv(dataset3)\n",
    "df_sinteticas = pd.DataFrame(sinteticas)\n",
    "\n",
    "df_sinteticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6bb7f8-3ba8-4792-bc41-7b264eb66e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
